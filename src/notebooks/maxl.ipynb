{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Dict\n",
    "\n",
    "class Graph:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes: pl.DataFrame,\n",
    "        edges: pl.DataFrame,\n",
    "        map_id: Dict[int, int]    \n",
    "    ) -> None:\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.map_id = map_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from typing import Dict, List\n",
    "import networkx as nx\n",
    "import networkit as nk\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataNetWork:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df_features: pl.DataFrame, \n",
    "        df_edges: pl.DataFrame, \n",
    "        df_classes: pl.DataFrame, \n",
    "        train_mask: np.array, \n",
    "        val_mask: np.array, \n",
    "        test_mask: np.array, \n",
    "        directed: bool = False\n",
    "    ):\n",
    "        \n",
    "        self.df_features = df_features\n",
    "        self.df_edges = df_edges\n",
    "        self.df_classes = df_classes\n",
    "        self.directed = directed\n",
    "        \n",
    "        self.graph: Graph = self._set_up_network_info()\n",
    "\n",
    "        self.fraud_dict = dict(\n",
    "            zip(\n",
    "                pl.from_pandas(df_features[\"transid\"].to_pandas().map(self.graph.map_id)),\n",
    "                df_features[\"class\"]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.train_mask = train_mask\n",
    "        self.val_mask = val_mask\n",
    "        self.test_mask = test_mask\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _set_up_network_info(self) -> Graph:\n",
    "        nodes = self.df_features.select(\n",
    "            pl.col('transid')\n",
    "        )\n",
    "        \n",
    "        map_id = {i:j for i,j in enumerate((nodes\n",
    "                                            .to_series()\n",
    "                                            .to_list()))} \n",
    "        \n",
    "        edges = self.df_edges.select(\n",
    "            pl.col('current_transid'),\n",
    "            pl.col('next_transid')\n",
    "        )\n",
    "\n",
    "        if not self.directed:\n",
    "            map_id = {j:i for i,j in enumerate((nodes\n",
    "                                            .to_series()\n",
    "                                            .to_list()))} \n",
    "            \n",
    "            # nodes = nodes.with_columns(\n",
    "            #     pl.col('transid').map_dict(map_id).cast(pl.Int64)\n",
    "            # )\n",
    "            \n",
    "            nodes = nodes.to_pandas()\n",
    "            nodes['transid'] = nodes['transid'].map(map_id).astype(np.int64)\n",
    "            nodes = pl.from_pandas(nodes)\n",
    "            \n",
    "            # edges = edges.with_columns(\n",
    "            #     pl.col('current_transid').map_dict(map_id).cast(pl.Int64),\n",
    "            #     pl.col('next_transid').map_dict(map_id).cast(pl.Int64)\n",
    "            # )\n",
    "            \n",
    "            edges = edges.to_pandas()\n",
    "            \n",
    "            edges_direct = edges[['current_transid', 'next_transid']]\n",
    "            edges_reverse = edges_direct[['next_transid', 'current_transid']]\n",
    "            edges_reverse.columns = ['current_transid', 'next_transid']\n",
    "            \n",
    "            edges = pd.concat([edges_direct, edges_reverse], axis=0)\n",
    "            \n",
    "            edges['current_transid'] = edges['current_transid'].map(map_id).astype(np.int64)\n",
    "            edges['next_transid'] = edges['next_transid'].map(map_id).astype(np.int64)\n",
    "            edges = pl.from_pandas(edges)\n",
    "            \n",
    "\n",
    "        \n",
    "        return Graph(\n",
    "            nodes=nodes,\n",
    "            edges=edges,\n",
    "            map_id=map_id\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_network_nx(self) -> nx.DiGraph:\n",
    "        edges_zipped = zip(self.graph.edges['current_transid'], self.graph.edges['next_transid'])\n",
    "        \n",
    "        if self.directed:\n",
    "            G_nx = nx.DiGraph()\n",
    "        else: \n",
    "            G_nx = nx.Graph()\n",
    "        \n",
    "        G_nx.add_nodes_from(self.graph.nodes)\n",
    "        G_nx.add_edges_from(edges_zipped)\n",
    "        \n",
    "        return G_nx     \n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_network_nk(self) -> nx.DiGraph:\n",
    "        edges_zipped = zip(self.graph.edges['current_transid'], self.graph.edges['next_transid'])\n",
    "        \n",
    "        G_nk = nk.Graph(len(self.graph.nodes), directed = self.directed)\n",
    "        \n",
    "        for u,v in edges_zipped:\n",
    "            G_nk.addEdge(u,v)\n",
    "            \n",
    "        return G_nk \n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_network_torch(self) -> Data:\n",
    "        labels = self.df_features['class']\n",
    "        features = self.df_features.to_pandas().drop(columns=['transid', 'class'])\n",
    "        \n",
    "        x = torch.tensor(np.array(features.to_numpy(), dtype=float), dtype=torch.float)\n",
    "        if x.size()[1] == 0:\n",
    "            x = torch.ones(x.size()[0], 1)\n",
    "        \n",
    "        x = x[:, 1:94]\n",
    "        y = torch.tensor(np.array(labels.to_numpy(), dtype=np.int64), dtype=torch.int64)\n",
    "        \n",
    "        # Reformat and convert to tensor\n",
    "        edge_index = np.array(self.graph.edges.to_numpy()).T \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        \n",
    "        #create weights tensor with same shape of edge_index\n",
    "        weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.float) \n",
    "        \n",
    "        # Create pyG dataset\n",
    "        data = Data(x=x, y=y, edge_index=edge_index)\n",
    "\n",
    "        if self.train_mask is not None:\n",
    "            data.train_mask = torch.tensor(self.train_mask, dtype=torch.bool)\n",
    "        if self.val_mask is not None:\n",
    "            data.val_mask = torch.tensor(self.val_mask, dtype=torch.bool)\n",
    "        if self.test_mask is not None:\n",
    "            data.test_mask = torch.tensor(self.test_mask, dtype=torch.bool)\n",
    "        \n",
    "        return data \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_features(\n",
    "            self, \n",
    "            full=False\n",
    "        ) -> pl.DataFrame:\n",
    "        \n",
    "        if full:\n",
    "            X = self.df_features[self.df_features.columns[2: 167]]\n",
    "        else:\n",
    "            X = self.df_features[self.df_features.columns[2: 95]]\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_features_torch(\n",
    "        self, \n",
    "        full=False\n",
    "    ) -> torch.tensor:\n",
    "        \n",
    "        X = self.get_features(full)\n",
    "        X = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "        \n",
    "        return(X)\n",
    "\n",
    "\n",
    "\n",
    "    def get_train_test_split_intrinsic(\n",
    "        self, \n",
    "        train_mask: np.array, \n",
    "        test_mask: np.array, \n",
    "        device: str = 'cpu'\n",
    "    ) -> List[torch.tensor]:\n",
    "        \n",
    "        X: pl.DataFrame = self.get_features()\n",
    "        y: pl.Series = self.df_features['class']\n",
    "\n",
    "        X_train = X.filter(\n",
    "            pl.Series(train_mask.tolist())\n",
    "        )\n",
    "        y_train = y.filter(\n",
    "            pl.Series(train_mask.tolist())\n",
    "        )\n",
    "\n",
    "        X_test = X.filter(\n",
    "            pl.Series(test_mask.tolist())\n",
    "        )\n",
    "        y_test = y.filter(\n",
    "            pl.Series(test_mask.tolist())\n",
    "        )\n",
    "\n",
    "        X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32).to(device)\n",
    "        y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long).to(device)\n",
    "\n",
    "        X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32).to(device)\n",
    "        y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long).to(device)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "    def get_fraud_dict(self) -> Dict[int, int]:\n",
    "        return self.fraud_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_masks(self) -> List[np.array]:\n",
    "        return self.train_mask, self.val_mask, self.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_FEAT_NAME = {\n",
    "        'column_1': 'transid',\n",
    "        'column_2': 'time_steps',\n",
    "}\n",
    "\n",
    "CONFIG_FILE = 'conf/development.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipticLoader:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path_features: str,\n",
    "        path_edgelist: str,\n",
    "        path_classes: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self.path_features = path_features\n",
    "        self.path_edgelist = path_edgelist\n",
    "        self.path_classes = path_classes\n",
    "    \n",
    "    \n",
    "\n",
    "    def load(self) -> DataNetWork:\n",
    "        \n",
    "        feat_df = pl.read_csv(\n",
    "            self.path_features, \n",
    "            has_header=False\n",
    "        )\n",
    "    \n",
    "        second_feat_name = {f'column_{i}': f'feature_{i-2}' for i in range(3, feat_df.shape[1] + 1)}\n",
    "        converted_feature_names = {**FIRST_FEAT_NAME, **second_feat_name}\n",
    "        feat_df = feat_df.rename(converted_feature_names)\n",
    "\n",
    "        edge_df = pl.read_csv(\n",
    "            self.path_edgelist, \n",
    "            new_columns=['current_transid', 'next_transid']\n",
    "        \n",
    "        )\n",
    "        class_df = pl.read_csv(\n",
    "            self.path_classes,\n",
    "            new_columns=['transid', 'class']\n",
    "        )\n",
    "\n",
    "        mapping = {'unknown': 2, '1': 1, '2': 0}\n",
    "        mapper = pl.DataFrame({\n",
    "            \"class\": list(mapping.keys()),\n",
    "            \"new_class\": list(mapping.values())\n",
    "        })\n",
    "        class_df = class_df.join(mapper, on='class', how='left').drop('class').rename({'new_class': 'class'})\n",
    "        feat_df = feat_df.join(class_df, on='transid', how='left')\n",
    "        y = torch.from_numpy(class_df['class'].to_numpy())\n",
    "\n",
    "        # Timestamp based split:\n",
    "        time_step = torch.from_numpy(feat_df['time_steps'].to_numpy())\n",
    "        train_mask = (time_step < 30) & (y != 2)\n",
    "        val_mask = (time_step >= 30) & (time_step < 40) & (y != 2) \n",
    "        test_mask = (time_step >= 40) & (y != 2)\n",
    "\n",
    "        network = DataNetWork(\n",
    "            feat_df, \n",
    "            edge_df, \n",
    "            class_df,\n",
    "            train_mask=train_mask, \n",
    "            val_mask=val_mask, \n",
    "            test_mask=test_mask\n",
    "        )\n",
    "\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = EllipticLoader(\n",
    "    path_classes='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv',\n",
    "    path_edgelist='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv',\n",
    "    path_features='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_features.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = e.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = network.get_network_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(93, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DecoderLinear(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            embedding_dim: int, \n",
    "            output_dim: int=2\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.layer1 = nn.Linear(embedding_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        embedding, \n",
    "        normalize=False\n",
    "    ):\n",
    "        if normalize:\n",
    "            embedding = self.layer_norm(embedding)\n",
    "        h = self.layer1(embedding)\n",
    "        h = self.softmax(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_features: int, \n",
    "            hidden_dim: int, \n",
    "            embedding_dim: int, \n",
    "            output_dim: int= 1, \n",
    "            n_layers: int = 3, \n",
    "            dropout_rate: float = 0\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.gcn_hidden = nn.ModuleList()\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        if n_layers == 1:\n",
    "            self.gcn1 = GCNConv(num_features, embedding_dim)\n",
    "        else:\n",
    "            self.gcn1 = GCNConv(num_features, hidden_dim)\n",
    "            for _ in range(n_layers - 2): \n",
    "                self.gcn_hidden.append(GCNConv(hidden_dim, hidden_dim))\n",
    "            self.gcn2 = GCNConv(hidden_dim, embedding_dim)\n",
    "            \n",
    "        self.out = DecoderLinear(self.embedding_dim, self.output_dim)\n",
    "        \n",
    "    def encode(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        edge_index: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        h = self.gcn1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        if self.n_layers > 1:\n",
    "            for layer in self.gcn_hidden:\n",
    "                h = layer(h, edge_index)\n",
    "                h = F.relu(h)\n",
    "                h = self.dropout(h)\n",
    "            h = self.gcn2(h, edge_index)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def node_classification(\n",
    "        self, \n",
    "        z: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        output = self.out(z)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def link_prediction(\n",
    "        self,\n",
    "        z: torch.Tensor,\n",
    "        edge_label_index: torch.Tensor\n",
    "        ) -> torch.Tensor:\n",
    "\n",
    "        output = (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AdaDWLoss(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        T: float\n",
    "    ) -> None:\n",
    "        self.T = T\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        loss_trains: List[torch.Tensor], \n",
    "        loss_vals: List[torch.Tensor]\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        weights = 1 - loss_trains / loss_vals\n",
    "        lambda_coeff = torch.exp(weights / self.T) / torch.sum(torch.exp(weights / self.T))\n",
    "        \n",
    "        loss_tasks = torch.dot(lambda_coeff, loss_trains)\n",
    "        \n",
    "        return loss_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        gamma=0, \n",
    "        alpha=None, \n",
    "        size_average=True\n",
    "    ) -> None:\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input: torch.Tensor, \n",
    "        target: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m \u001b[43msplit\u001b[49m(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "train, val, test = split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edge_index = negative_sampling(\n",
    "            edge_index=train.edge_index, num_nodes=train.num_nodes,\n",
    "            num_neg_samples=train.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "edge_label_index = torch.cat(\n",
    "    [train.edge_label_index, neg_edge_index],\n",
    "    dim=-1,\n",
    ")\n",
    "edge_label = torch.cat([\n",
    "    train.edge_label,\n",
    "    train.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim=217\n",
    "embedding_dim=87\n",
    "n_layers=3\n",
    "n_features=93\n",
    "output_dim=2\n",
    "dropout_rate=0.057\n",
    "heads=5\n",
    "\n",
    "lr=0.0864\n",
    "epochs=500\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(\n",
    "        num_features=n_features,\n",
    "        hidden_dim=hidden_dim,\n",
    "        embedding_dim=embedding_dim,\n",
    "        output_dim=output_dim,\n",
    "        n_layers=n_layers,\n",
    "        dropout_rate=dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gcn.encode(train.x, train.edge_index)\n",
    "out = gcn.link_prediction(z, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from multiprocessing import Pool\n",
    "\n",
    "loader = NeighborLoader(\n",
    "                data=train, \n",
    "                num_neighbors=[-1]*n_layers, \n",
    "                input_nodes=train.train_mask, \n",
    "                batch_size=batch_size, \n",
    "                shuffle=True, \n",
    "                num_workers=Pool()._processes\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(gcn.parameters(), lr=lr)\n",
    "adadw = AdaDWLoss(T=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([398406])\n",
      "torch.Size([398406])\n",
      "torch.Size([203769, 87])\n",
      "torch.Size([398406, 87])\n",
      "torch.Size([398406, 87])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "\n",
    "        \n",
    "    gcn.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = gcn.encode(train.x.to(device), train.edge_index.to(device))\n",
    "    \n",
    "    out_nc = gcn.node_classification(z)\n",
    "    \n",
    "    neg_edge_index = negative_sampling(\n",
    "                edge_index=train.edge_index.to(device), \n",
    "                num_nodes=train.num_nodes,\n",
    "                num_neg_samples=train.edge_label_index.size(1), method='sparse'\n",
    "            )\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    ).to(device)\n",
    "    edge_label = torch.cat([\n",
    "        train.edge_label.squeeze(dim=0),\n",
    "        train.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0).to(device)\n",
    "    \n",
    "\n",
    "    out_lp = gcn.link_prediction(z, edge_label_index).view(-1)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss(gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 1, [203769], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.rand([203769, 2])[:, 1].reshape(-1, 1), torch.randint(0, 1, [203769, 1], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
