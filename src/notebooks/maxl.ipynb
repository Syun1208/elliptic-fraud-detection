{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Dict\n",
    "\n",
    "class Graph:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes: pl.DataFrame,\n",
    "        edges: pl.DataFrame,\n",
    "        map_id: Dict[int, int]    \n",
    "    ) -> None:\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.map_id = map_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from typing import Dict, List\n",
    "import networkx as nx\n",
    "import networkit as nk\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataNetWork:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df_features: pl.DataFrame, \n",
    "        df_edges: pl.DataFrame, \n",
    "        df_classes: pl.DataFrame, \n",
    "        train_mask: np.array, \n",
    "        val_mask: np.array, \n",
    "        test_mask: np.array, \n",
    "        directed: bool = False\n",
    "    ):\n",
    "        \n",
    "        self.df_features = df_features\n",
    "        self.df_edges = df_edges\n",
    "        self.df_classes = df_classes\n",
    "        self.directed = directed\n",
    "        \n",
    "        self.graph: Graph = self._set_up_network_info()\n",
    "\n",
    "        self.fraud_dict = dict(\n",
    "            zip(\n",
    "                pl.from_pandas(df_features[\"transid\"].to_pandas().map(self.graph.map_id)),\n",
    "                df_features[\"class\"]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.train_mask = train_mask\n",
    "        self.val_mask = val_mask\n",
    "        self.test_mask = test_mask\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _set_up_network_info(self) -> Graph:\n",
    "        nodes = self.df_features.select(\n",
    "            pl.col('transid')\n",
    "        )\n",
    "        \n",
    "        map_id = {i:j for i,j in enumerate((nodes\n",
    "                                            .to_series()\n",
    "                                            .to_list()))} \n",
    "        \n",
    "        edges = self.df_edges.select(\n",
    "            pl.col('current_transid'),\n",
    "            pl.col('next_transid')\n",
    "        )\n",
    "\n",
    "        if not self.directed:\n",
    "            map_id = {j:i for i,j in enumerate((nodes\n",
    "                                            .to_series()\n",
    "                                            .to_list()))} \n",
    "            \n",
    "            # nodes = nodes.with_columns(\n",
    "            #     pl.col('transid').map_dict(map_id).cast(pl.Int64)\n",
    "            # )\n",
    "            \n",
    "            nodes = nodes.to_pandas()\n",
    "            nodes['transid'] = nodes['transid'].map(map_id).astype(np.int64)\n",
    "            nodes = pl.from_pandas(nodes)\n",
    "            \n",
    "            # edges = edges.with_columns(\n",
    "            #     pl.col('current_transid').map_dict(map_id).cast(pl.Int64),\n",
    "            #     pl.col('next_transid').map_dict(map_id).cast(pl.Int64)\n",
    "            # )\n",
    "            \n",
    "            edges = edges.to_pandas()\n",
    "            \n",
    "            edges_direct = edges[['current_transid', 'next_transid']]\n",
    "            edges_reverse = edges_direct[['next_transid', 'current_transid']]\n",
    "            edges_reverse.columns = ['current_transid', 'next_transid']\n",
    "            \n",
    "            edges = pd.concat([edges_direct, edges_reverse], axis=0)\n",
    "            \n",
    "            edges['current_transid'] = edges['current_transid'].map(map_id).astype(np.int64)\n",
    "            edges['next_transid'] = edges['next_transid'].map(map_id).astype(np.int64)\n",
    "            edges = pl.from_pandas(edges)\n",
    "            \n",
    "\n",
    "        \n",
    "        return Graph(\n",
    "            nodes=nodes,\n",
    "            edges=edges,\n",
    "            map_id=map_id\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_network_nx(self) -> nx.DiGraph:\n",
    "        edges_zipped = zip(self.graph.edges['current_transid'], self.graph.edges['next_transid'])\n",
    "        \n",
    "        if self.directed:\n",
    "            G_nx = nx.DiGraph()\n",
    "        else: \n",
    "            G_nx = nx.Graph()\n",
    "        \n",
    "        G_nx.add_nodes_from(self.graph.nodes)\n",
    "        G_nx.add_edges_from(edges_zipped)\n",
    "        \n",
    "        return G_nx     \n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_network_nk(self) -> nx.DiGraph:\n",
    "        edges_zipped = zip(self.graph.edges['current_transid'], self.graph.edges['next_transid'])\n",
    "        \n",
    "        G_nk = nk.Graph(len(self.graph.nodes), directed = self.directed)\n",
    "        \n",
    "        for u,v in edges_zipped:\n",
    "            G_nk.addEdge(u,v)\n",
    "            \n",
    "        return G_nk \n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_network_torch(self) -> Data:\n",
    "        labels = self.df_features['class']\n",
    "        features = self.df_features.to_pandas().drop(columns=['transid', 'class'])\n",
    "        \n",
    "        x = torch.tensor(np.array(features.to_numpy(), dtype=float), dtype=torch.float)\n",
    "        if x.size()[1] == 0:\n",
    "            x = torch.ones(x.size()[0], 1)\n",
    "        \n",
    "        x = x[:, 1:94]\n",
    "        y = torch.tensor(np.array(labels.to_numpy(), dtype=np.int64), dtype=torch.int64)\n",
    "        \n",
    "        # Reformat and convert to tensor\n",
    "        edge_index = np.array(self.graph.edges.to_numpy()).T \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        \n",
    "        #create weights tensor with same shape of edge_index\n",
    "        weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.float) \n",
    "        \n",
    "        # Create pyG dataset\n",
    "        data = Data(x=x, y=y, edge_index=edge_index)\n",
    "\n",
    "        if self.train_mask is not None:\n",
    "            data.train_mask = torch.tensor(self.train_mask, dtype=torch.bool)\n",
    "        if self.val_mask is not None:\n",
    "            data.val_mask = torch.tensor(self.val_mask, dtype=torch.bool)\n",
    "        if self.test_mask is not None:\n",
    "            data.test_mask = torch.tensor(self.test_mask, dtype=torch.bool)\n",
    "        \n",
    "        return data \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_features(\n",
    "            self, \n",
    "            full=False\n",
    "        ) -> pl.DataFrame:\n",
    "        \n",
    "        if full:\n",
    "            X = self.df_features[self.df_features.columns[2: 167]]\n",
    "        else:\n",
    "            X = self.df_features[self.df_features.columns[2: 95]]\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_features_torch(\n",
    "        self, \n",
    "        full=False\n",
    "    ) -> torch.tensor:\n",
    "        \n",
    "        X = self.get_features(full)\n",
    "        X = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "        \n",
    "        return(X)\n",
    "\n",
    "\n",
    "\n",
    "    def get_train_test_split_intrinsic(\n",
    "        self, \n",
    "        train_mask: np.array, \n",
    "        test_mask: np.array, \n",
    "        device: str = 'cpu'\n",
    "    ) -> List[torch.tensor]:\n",
    "        \n",
    "        X: pl.DataFrame = self.get_features()\n",
    "        y: pl.Series = self.df_features['class']\n",
    "\n",
    "        X_train = X.filter(\n",
    "            pl.Series(train_mask.tolist())\n",
    "        )\n",
    "        y_train = y.filter(\n",
    "            pl.Series(train_mask.tolist())\n",
    "        )\n",
    "\n",
    "        X_test = X.filter(\n",
    "            pl.Series(test_mask.tolist())\n",
    "        )\n",
    "        y_test = y.filter(\n",
    "            pl.Series(test_mask.tolist())\n",
    "        )\n",
    "\n",
    "        X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32).to(device)\n",
    "        y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long).to(device)\n",
    "\n",
    "        X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32).to(device)\n",
    "        y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long).to(device)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "    def get_fraud_dict(self) -> Dict[int, int]:\n",
    "        return self.fraud_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_masks(self) -> List[np.array]:\n",
    "        return self.train_mask, self.val_mask, self.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_FEAT_NAME = {\n",
    "        'column_1': 'transid',\n",
    "        'column_2': 'time_steps',\n",
    "}\n",
    "\n",
    "CONFIG_FILE = 'conf/development.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipticLoader:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path_features: str,\n",
    "        path_edgelist: str,\n",
    "        path_classes: str\n",
    "    ) -> None:\n",
    "        \n",
    "        self.path_features = path_features\n",
    "        self.path_edgelist = path_edgelist\n",
    "        self.path_classes = path_classes\n",
    "    \n",
    "    \n",
    "\n",
    "    def load(self) -> DataNetWork:\n",
    "        \n",
    "        feat_df = pl.read_csv(\n",
    "            self.path_features, \n",
    "            has_header=False\n",
    "        )\n",
    "    \n",
    "        second_feat_name = {f'column_{i}': f'feature_{i-2}' for i in range(3, feat_df.shape[1] + 1)}\n",
    "        converted_feature_names = {**FIRST_FEAT_NAME, **second_feat_name}\n",
    "        feat_df = feat_df.rename(converted_feature_names)\n",
    "\n",
    "        edge_df = pl.read_csv(\n",
    "            self.path_edgelist, \n",
    "            new_columns=['current_transid', 'next_transid']\n",
    "        \n",
    "        )\n",
    "        class_df = pl.read_csv(\n",
    "            self.path_classes,\n",
    "            new_columns=['transid', 'class']\n",
    "        )\n",
    "\n",
    "        mapping = {'unknown': 2, '1': 1, '2': 0}\n",
    "        mapper = pl.DataFrame({\n",
    "            \"class\": list(mapping.keys()),\n",
    "            \"new_class\": list(mapping.values())\n",
    "        })\n",
    "        class_df = class_df.join(mapper, on='class', how='left').drop('class').rename({'new_class': 'class'})\n",
    "        feat_df = feat_df.join(class_df, on='transid', how='left')\n",
    "        y = torch.from_numpy(class_df['class'].to_numpy())\n",
    "\n",
    "        # Timestamp based split:\n",
    "        time_step = torch.from_numpy(feat_df['time_steps'].to_numpy())\n",
    "        train_mask = (time_step < 30) & (y != 2)\n",
    "        val_mask = (time_step >= 30) & (time_step < 40) & (y != 2) \n",
    "        test_mask = (time_step >= 40) & (y != 2)\n",
    "\n",
    "        network = DataNetWork(\n",
    "            feat_df, \n",
    "            edge_df, \n",
    "            class_df,\n",
    "            train_mask=train_mask, \n",
    "            val_mask=val_mask, \n",
    "            test_mask=test_mask\n",
    "        )\n",
    "\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = EllipticLoader(\n",
    "    path_classes='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv',\n",
    "    path_edgelist='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv',\n",
    "    path_features='/Users/phamminhlong/Desktop/paper/data/elliptic_bitcoin_dataset/elliptic_txs_features.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = e.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = network.get_network_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(93, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "z = model.encode(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      2,      4,  ..., 202042, 201368, 201756],\n",
       "        [     1,      3,      5,  ..., 201921, 201480, 201954]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[:, :data.edge_index.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = network.df_edges\n",
    "feats = network.df_features\n",
    "label = network.df_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (234_355, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>current_transid</th><th>next_transid</th><th>current_class</th><th>next_class</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>230425980</td><td>5530458</td><td>2</td><td>2</td></tr><tr><td>232022460</td><td>232438397</td><td>2</td><td>0</td></tr><tr><td>230460314</td><td>230459870</td><td>2</td><td>2</td></tr><tr><td>230333930</td><td>230595899</td><td>2</td><td>2</td></tr><tr><td>232013274</td><td>232029206</td><td>2</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>158365409</td><td>157930723</td><td>1</td><td>0</td></tr><tr><td>188708874</td><td>188708879</td><td>2</td><td>2</td></tr><tr><td>157659064</td><td>157659046</td><td>2</td><td>2</td></tr><tr><td>87414554</td><td>106877725</td><td>2</td><td>0</td></tr><tr><td>158589452</td><td>158589457</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (234_355, 4)\n",
       "┌─────────────────┬──────────────┬───────────────┬────────────┐\n",
       "│ current_transid ┆ next_transid ┆ current_class ┆ next_class │\n",
       "│ ---             ┆ ---          ┆ ---           ┆ ---        │\n",
       "│ i64             ┆ i64          ┆ i64           ┆ i64        │\n",
       "╞═════════════════╪══════════════╪═══════════════╪════════════╡\n",
       "│ 230425980       ┆ 5530458      ┆ 2             ┆ 2          │\n",
       "│ 232022460       ┆ 232438397    ┆ 2             ┆ 0          │\n",
       "│ 230460314       ┆ 230459870    ┆ 2             ┆ 2          │\n",
       "│ 230333930       ┆ 230595899    ┆ 2             ┆ 2          │\n",
       "│ 232013274       ┆ 232029206    ┆ 2             ┆ 0          │\n",
       "│ …               ┆ …            ┆ …             ┆ …          │\n",
       "│ 158365409       ┆ 157930723    ┆ 1             ┆ 0          │\n",
       "│ 188708874       ┆ 188708879    ┆ 2             ┆ 2          │\n",
       "│ 157659064       ┆ 157659046    ┆ 2             ┆ 2          │\n",
       "│ 87414554        ┆ 106877725    ┆ 2             ┆ 0          │\n",
       "│ 158589452       ┆ 158589457    ┆ 2             ┆ 2          │\n",
       "└─────────────────┴──────────────┴───────────────┴────────────┘"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = edges.rename({'current_transid': 'transid'})\n",
    "edges = edges.join(label, on='transid', how='left')\n",
    "edges = edges.rename({'transid': 'current_transid', 'class': 'current_class', 'next_transid': 'transid'})\n",
    "edges = edges.join(label, on='transid', how='left')\n",
    "edges = edges.rename({'transid': 'next_transid', 'class': 'next_class'})\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label = edges.with_columns(\n",
    "    pl.when(pl.col('current_class') == pl.col('next_class'))\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias('edge_label')\n",
    ").filter(\n",
    "    pl.col('edge_label') == 1\n",
    ").drop(\n",
    "    ['current_class', 'next_class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_label = torch.from_numpy(edge_label.select(['current_transid', 'next_transid']).to_numpy()).reshape(2, -1)\n",
    "edge_label = torch.from_numpy(edge_label.select(['edge_label']).to_numpy()).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([203769, 93])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edge_index = negative_sampling(\n",
    "    edge_index=data.edge_index, num_nodes=203769,\n",
    "    num_neg_samples=edge_index_label.size(1), method='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[166810, 143306,   3722,  ..., 129819, 156595, 142563],\n",
       "        [ 98295, 125591, 144669,  ..., 136886, 114337,  66724]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([203769, 93]), torch.Size([2, 468710]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape, data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Weights: tensor([1.6623, 0.7733, 0.5644])\n",
      "Total Weighted Loss: tensor(1.6098)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_task_weights(Lv, Lt, T, K):\n",
    "    \"\"\"\n",
    "    Calculate the adaptive dynamic weights for tasks.\n",
    "    \n",
    "    Args:\n",
    "    - Lv: List of validation losses for each task (list of tensors)\n",
    "    - Lt: List of training losses for each task (list of tensors)\n",
    "    - T: Softness parameter for task weights\n",
    "    - K: Number of tasks\n",
    "    \n",
    "    Returns:\n",
    "    - lambda_k: List of calculated weights for each task (list of tensors)\n",
    "    \"\"\"\n",
    "    lambda_k = []\n",
    "    for k in range(K):\n",
    "        # Calculate wk(t - 1)\n",
    "        wk = 1 - Lv[k] / Lt[k]\n",
    "        \n",
    "        # Calculate the denominator for normalization\n",
    "        exp_weights = [torch.exp(wi / T) for wi in lambda_k]\n",
    "        denominator = sum(exp_weights) if exp_weights else 1.0\n",
    "        \n",
    "        # Calculate lambda_k(t)\n",
    "        lambda_k.append(torch.exp(wk / T) / denominator)\n",
    "    \n",
    "    # Normalize lambda_k to ensure sum is K\n",
    "    lambda_k = torch.tensor(lambda_k)\n",
    "    lambda_k = lambda_k / lambda_k.sum() * K\n",
    "    \n",
    "    return lambda_k\n",
    "\n",
    "def compute_weighted_loss(Ln, Lp, Ll, lambda_n, lambda_p, lambda_l):\n",
    "    \"\"\"\n",
    "    Compute the weighted loss function.\n",
    "    \n",
    "    Args:\n",
    "    - Ln: Loss for node classification\n",
    "    - Lp: Loss for node pair classification\n",
    "    - Ll: Loss for link prediction\n",
    "    - lambda_n: Weight for node classification\n",
    "    - lambda_p: Weight for node pair classification\n",
    "    - lambda_l: Weight for link prediction\n",
    "    \n",
    "    Returns:\n",
    "    - total_loss: Weighted loss\n",
    "    \"\"\"\n",
    "    total_loss = lambda_n * Ln + lambda_p * Lp + lambda_l * Ll\n",
    "    return total_loss\n",
    "\n",
    "# Example usage\n",
    "K = 3  # Number of tasks\n",
    "T = 0.5  # Softness parameter\n",
    "\n",
    "# Example loss values (tensors for demonstration)\n",
    "Lt = [torch.tensor(0.5), torch.tensor(0.6), torch.tensor(0.4)]  # Training losses\n",
    "Lv = [torch.tensor(0.7), torch.tensor(0.8), torch.tensor(0.5)]  # Validation losses\n",
    "\n",
    "# Calculate adaptive weights\n",
    "lambda_k = calculate_task_weights(Lv, Lt, T, K)\n",
    "\n",
    "# Example loss for each task\n",
    "Ln = torch.tensor(0.6)  # Node classification loss\n",
    "Lp = torch.tensor(0.5)  # Node pair classification loss\n",
    "Ll = torch.tensor(0.4)  # Link prediction loss\n",
    "\n",
    "# Calculate weighted loss\n",
    "lambda_n, lambda_p, lambda_l = lambda_k[0], lambda_k[1], lambda_k[2]\n",
    "total_loss = compute_weighted_loss(Ln, Lp, Ll, lambda_n, lambda_p, lambda_l)\n",
    "\n",
    "print(\"Adaptive Weights:\", lambda_k)\n",
    "print(\"Total Weighted Loss:\", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_train = torch.tensor([0.5, 0.6, 0.4])  # Training losses\n",
    "loss_val = torch.tensor([0.7, 0.8, 0.5])\n",
    "\n",
    "weights = 1 - loss_train / loss_val\n",
    "lambda_coeff = torch.exp(weights / 3) / torch.sum(torch.exp(weights / 3))\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5006)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(lambda_coeff, loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3378, 0.3338, 0.3283])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
